{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddcce7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autor: Alejandro Gerena\n",
    "# Objetivo: Aplicar limpieza de datos según problemas identificados y \n",
    "#           exportar a formato JSON estructurado\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cdbbf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ETAPA 1: CARGA Y EXPLORACIÓN INICIAL\n",
    "# ============================================================================\n",
    "\n",
    "def cargar_dataset(filename: str) -> pd.DataFrame | None:\n",
    "    try:\n",
    "        base_dir = os.getcwd()\n",
    "        file_path = os.path.join(base_dir, \"..\", \"data\", filename)\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"El archivo {file_path} no existe.\")\n",
    "\n",
    "        ext = os.path.splitext(filename)[1].lower()\n",
    "\n",
    "        if ext == \".csv\":\n",
    "            # Intentar abrir con UTF-8, si falla usar latin-1\n",
    "            for encoding in [\"utf-8\", \"latin-1\"]:\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding=encoding) as f:\n",
    "                        sample = f.read(2048)\n",
    "                        sniffer = csv.Sniffer()\n",
    "                        dialect = sniffer.sniff(sample)\n",
    "                        detected_sep = dialect.delimiter\n",
    "\n",
    "                    data = pd.read_csv(file_path, encoding=encoding, sep=detected_sep)\n",
    "                    break  # Si carga correctamente, salir del bucle\n",
    "                except UnicodeDecodeError:\n",
    "                    continue\n",
    "            else:\n",
    "                raise UnicodeDecodeError(\"No se pudo decodificar el archivo con utf-8 ni latin-1\")\n",
    "\n",
    "        elif ext in [\".xls\", \".xlsx\"]:\n",
    "            data = pd.read_excel(file_path)\n",
    "        else:\n",
    "            raise ValueError(\"Formato de archivo no soportado. Use CSV o Excel (.xls, .xlsx).\")\n",
    "\n",
    "        print(f\">>> El archivo '{filename}' se cargó correctamente. Filas: {data.shape[0]}, Columnas: {data.shape[1]}\")\n",
    "        return data\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error de formato: {e}\")\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error inesperado: {e}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def explorar_dataset(df):\n",
    "    \"\"\"\n",
    "    Muestra información básica del dataset\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXPLORACIÓN INICIAL DEL DATASET\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n1. Primeras filas:\")\n",
    "    display(df.head(3))\n",
    "    \n",
    "    print(\"\\n2. Información de columnas:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\n3. Valores nulos por columna:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    print(\"\\n4. Valores únicos en columnas clave:\")\n",
    "    for col in ['flightNumber', 'plane', 'dep_airport_code', 'arr_airport_code']:\n",
    "        if col in df.columns:\n",
    "            print(f\"  - {col}: {df[col].nunique()} valores únicos\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a918f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> El archivo 'infovuelos_sample.csv' se cargó correctamente. Filas: 39102, Columnas: 25\n",
      "\n",
      "================================================================================\n",
      "EXPLORACIÓN INICIAL DEL DATASET\n",
      "================================================================================\n",
      "\n",
      "1. Primeras filas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flightNumber</th>\n",
       "      <th>plane</th>\n",
       "      <th>dep_date</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>dep_airport_name</th>\n",
       "      <th>dep_airport_code</th>\n",
       "      <th>dep_terminal</th>\n",
       "      <th>dep_status</th>\n",
       "      <th>dep_weather_min</th>\n",
       "      <th>dep_weather_max</th>\n",
       "      <th>...</th>\n",
       "      <th>arr_airport_name</th>\n",
       "      <th>arr_airport_code</th>\n",
       "      <th>arr_terminal</th>\n",
       "      <th>arr_status</th>\n",
       "      <th>arr_weather_min</th>\n",
       "      <th>arr_weather_max</th>\n",
       "      <th>arr_weather_desc</th>\n",
       "      <th>arr_room</th>\n",
       "      <th>arr_belt</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HTY134</td>\n",
       "      <td>AWH</td>\n",
       "      <td>13/04/18</td>\n",
       "      <td>10:00</td>\n",
       "      <td>ALGECIRAS / HELIPUERTO</td>\n",
       "      <td>AEI</td>\n",
       "      <td>-</td>\n",
       "      <td>El vuelo ha despegado a las 10:03</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>CEUTA</td>\n",
       "      <td>JCU</td>\n",
       "      <td>-</td>\n",
       "      <td>El vuelo ha aterrizado a las 10:12</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>Lluvia</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2018-04-13 10:33:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HTY110</td>\n",
       "      <td>AWH</td>\n",
       "      <td>13/04/18</td>\n",
       "      <td>14:15</td>\n",
       "      <td>CEUTA</td>\n",
       "      <td>JCU</td>\n",
       "      <td>-</td>\n",
       "      <td>Llegada prevista a las 14:15</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>ALGECIRAS / HELIPUERTO</td>\n",
       "      <td>AEI</td>\n",
       "      <td>-</td>\n",
       "      <td>Salida prevista a las 14:35</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>Chubascos dispersos</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2018-04-13 10:33:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HTY112</td>\n",
       "      <td>AWH</td>\n",
       "      <td>13/04/18</td>\n",
       "      <td>15:05</td>\n",
       "      <td>ALGECIRAS / HELIPUERTO</td>\n",
       "      <td>AEI</td>\n",
       "      <td>-</td>\n",
       "      <td>Salida prevista a las 15:10</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>CEUTA</td>\n",
       "      <td>JCU</td>\n",
       "      <td>-</td>\n",
       "      <td>Llegada prevista a las 15:15</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>Lluvia</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2018-04-13 10:33:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  flightNumber plane  dep_date dep_time        dep_airport_name  \\\n",
       "0       HTY134   AWH  13/04/18    10:00  ALGECIRAS / HELIPUERTO   \n",
       "1       HTY110   AWH  13/04/18    14:15                   CEUTA   \n",
       "2       HTY112   AWH  13/04/18    15:05  ALGECIRAS / HELIPUERTO   \n",
       "\n",
       "  dep_airport_code dep_terminal                         dep_status  \\\n",
       "0              AEI            -  El vuelo ha despegado a las 10:03   \n",
       "1              JCU            -       Llegada prevista a las 14:15   \n",
       "2              AEI            -        Salida prevista a las 15:10   \n",
       "\n",
       "  dep_weather_min dep_weather_max  ...        arr_airport_name  \\\n",
       "0               9              16  ...                   CEUTA   \n",
       "1              11              17  ...  ALGECIRAS / HELIPUERTO   \n",
       "2               9              16  ...                   CEUTA   \n",
       "\n",
       "  arr_airport_code arr_terminal                          arr_status  \\\n",
       "0              JCU            -  El vuelo ha aterrizado a las 10:12   \n",
       "1              AEI            -         Salida prevista a las 14:35   \n",
       "2              JCU            -        Llegada prevista a las 15:15   \n",
       "\n",
       "  arr_weather_min arr_weather_max     arr_weather_desc arr_room arr_belt  \\\n",
       "0              11              17               Lluvia       -        -    \n",
       "1               9              16  Chubascos dispersos       -        -    \n",
       "2              11              17               Lluvia       -        -    \n",
       "\n",
       "             timestamp  \n",
       "0  2018-04-13 10:33:45  \n",
       "1  2018-04-13 10:33:47  \n",
       "2  2018-04-13 10:33:48  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Información de columnas:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39102 entries, 0 to 39101\n",
      "Data columns (total 25 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   flightNumber      39102 non-null  object\n",
      " 1   plane             39102 non-null  object\n",
      " 2   dep_date          39102 non-null  object\n",
      " 3   dep_time          39102 non-null  object\n",
      " 4   dep_airport_name  39102 non-null  object\n",
      " 5   dep_airport_code  39102 non-null  object\n",
      " 6   dep_terminal      39102 non-null  object\n",
      " 7   dep_status        39102 non-null  object\n",
      " 8   dep_weather_min   39102 non-null  object\n",
      " 9   dep_weather_max   39102 non-null  object\n",
      " 10  dep_weather_desc  39102 non-null  object\n",
      " 11  dep_counter       39102 non-null  object\n",
      " 12  dep_door          39102 non-null  object\n",
      " 13  arr_date          39102 non-null  object\n",
      " 14  arr_time          39102 non-null  object\n",
      " 15  arr_airport_name  39102 non-null  object\n",
      " 16  arr_airport_code  39102 non-null  object\n",
      " 17  arr_terminal      39102 non-null  object\n",
      " 18  arr_status        39102 non-null  object\n",
      " 19  arr_weather_min   39102 non-null  object\n",
      " 20  arr_weather_max   39102 non-null  object\n",
      " 21  arr_weather_desc  39102 non-null  object\n",
      " 22  arr_room          39102 non-null  object\n",
      " 23  arr_belt          39102 non-null  object\n",
      " 24  timestamp         39102 non-null  object\n",
      "dtypes: object(25)\n",
      "memory usage: 7.5+ MB\n",
      "None\n",
      "\n",
      "3. Valores nulos por columna:\n",
      "flightNumber        0\n",
      "plane               0\n",
      "dep_date            0\n",
      "dep_time            0\n",
      "dep_airport_name    0\n",
      "dep_airport_code    0\n",
      "dep_terminal        0\n",
      "dep_status          0\n",
      "dep_weather_min     0\n",
      "dep_weather_max     0\n",
      "dep_weather_desc    0\n",
      "dep_counter         0\n",
      "dep_door            0\n",
      "arr_date            0\n",
      "arr_time            0\n",
      "arr_airport_name    0\n",
      "arr_airport_code    0\n",
      "arr_terminal        0\n",
      "arr_status          0\n",
      "arr_weather_min     0\n",
      "arr_weather_max     0\n",
      "arr_weather_desc    0\n",
      "arr_room            0\n",
      "arr_belt            0\n",
      "timestamp           0\n",
      "dtype: int64\n",
      "\n",
      "4. Valores únicos en columnas clave:\n",
      "  - flightNumber: 3787 valores únicos\n",
      "  - plane: 59 valores únicos\n",
      "  - dep_airport_code: 41 valores únicos\n",
      "  - arr_airport_code: 275 valores únicos\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar carga y exploración\n",
    "# Cargar información de vuelos\n",
    "df_raw = cargar_dataset(\"infovuelos_sample.csv\")\n",
    "df_raw = explorar_dataset(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f3e808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROBLEMA 1: Detección de valores '-' como nulos\n",
      "================================================================================\n",
      "  - dep_date: 861 valores '-'\n",
      "  - dep_time: 861 valores '-'\n",
      "  - dep_terminal: 5846 valores '-'\n",
      "  - dep_status: 868 valores '-'\n",
      "  - dep_weather_min: 861 valores '-'\n",
      "  - dep_weather_max: 861 valores '-'\n",
      "  - dep_weather_desc: 861 valores '-'\n",
      "  - dep_counter: 861 valores '-'\n",
      "  - dep_door: 861 valores '-'\n",
      "  - arr_date: 12920 valores '-'\n",
      "  - arr_time: 12920 valores '-'\n",
      "  - arr_terminal: 19076 valores '-'\n",
      "  - arr_status: 12927 valores '-'\n",
      "  - arr_weather_min: 12920 valores '-'\n",
      "  - arr_weather_max: 12920 valores '-'\n",
      "  - arr_weather_desc: 12920 valores '-'\n",
      "  - arr_room: 12920 valores '-'\n",
      "  - arr_belt: 12920 valores '-'\n",
      "\n",
      "✓ Valores '-' reemplazados por NaN\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VALIDACIÓN PROBLEMA 1\n",
      "--------------------------------------------------------------------------------\n",
      "  Valores '-' antes: 135184\n",
      "  Valores '-' después: 0\n",
      "  ✓ VALIDACIÓN EXITOSA: Todos los '-' eliminados\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ETAPA 2: LIMPIEZA - PROBLEMA 1 (Valores nulos representados como \"-\")\n",
    "# ============================================================================\n",
    "\n",
    "def detectar_problema_1(df):\n",
    "    \"\"\"\n",
    "    Detecta columnas con valores \"-\" que deberían ser nulos\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROBLEMA 1: Detección de valores '-' como nulos\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    columnas_con_guion = []\n",
    "    for col in df.columns:\n",
    "        count_guion = (df[col] == '-').sum()\n",
    "        if count_guion > 0:\n",
    "            columnas_con_guion.append((col, count_guion))\n",
    "            print(f\"  - {col}: {count_guion} valores '-'\")\n",
    "    \n",
    "    return columnas_con_guion\n",
    "\n",
    "\n",
    "def limpiar_problema_1(df):\n",
    "    \"\"\"\n",
    "    Reemplaza valores \"-\" por NaN/None\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    df_clean.replace('-', np.nan, inplace=True)\n",
    "    print(\"\\n✓ Valores '-' reemplazados por NaN\")\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def validar_problema_1(df_original, df_limpio):\n",
    "    \"\"\"\n",
    "    Valida que los \"-\" se hayan eliminado correctamente\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"VALIDACIÓN PROBLEMA 1\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    guiones_antes = (df_original == '-').sum().sum()\n",
    "    guiones_despues = (df_limpio == '-').sum().sum()\n",
    "    \n",
    "    print(f\"  Valores '-' antes: {guiones_antes}\")\n",
    "    print(f\"  Valores '-' después: {guiones_despues}\")\n",
    "    \n",
    "    if guiones_despues == 0:\n",
    "        print(\"  ✓ VALIDACIÓN EXITOSA: Todos los '-' eliminados\")\n",
    "    else:\n",
    "        print(\"  ✗ VALIDACIÓN FALLIDA: Aún quedan valores '-'\")\n",
    "    \n",
    "    return guiones_despues == 0\n",
    "\n",
    "\n",
    "# Ejecutar limpieza Problema 1\n",
    "detectar_problema_1(df_raw)\n",
    "df_step1 = limpiar_problema_1(df_raw)\n",
    "validar_problema_1(df_raw, df_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97f5ac64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROBLEMA 2: Detección de duplicados\n",
      "================================================================================\n",
      "  Total de filas duplicadas: 24\n",
      "\n",
      "  Ejemplos de duplicados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flightNumber</th>\n",
       "      <th>plane</th>\n",
       "      <th>dep_date</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>dep_airport_name</th>\n",
       "      <th>dep_airport_code</th>\n",
       "      <th>dep_terminal</th>\n",
       "      <th>dep_status</th>\n",
       "      <th>dep_weather_min</th>\n",
       "      <th>dep_weather_max</th>\n",
       "      <th>...</th>\n",
       "      <th>arr_airport_name</th>\n",
       "      <th>arr_airport_code</th>\n",
       "      <th>arr_terminal</th>\n",
       "      <th>arr_status</th>\n",
       "      <th>arr_weather_min</th>\n",
       "      <th>arr_weather_max</th>\n",
       "      <th>arr_weather_desc</th>\n",
       "      <th>arr_room</th>\n",
       "      <th>arr_belt</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15589</th>\n",
       "      <td>AEA5001</td>\n",
       "      <td>ATR-72</td>\n",
       "      <td>14/04/18</td>\n",
       "      <td>09:20</td>\n",
       "      <td>MALAGA-COSTA DEL SOL</td>\n",
       "      <td>AGP</td>\n",
       "      <td>3</td>\n",
       "      <td>El vuelo ha despegado a las 09:14</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>MELILLA</td>\n",
       "      <td>MLN</td>\n",
       "      <td>T</td>\n",
       "      <td>Llegada prevista a las 09:50</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>Nubosidad variable</td>\n",
       "      <td>SLL</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-14 09:29:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15722</th>\n",
       "      <td>AEA5001</td>\n",
       "      <td>ATR-72</td>\n",
       "      <td>14/04/18</td>\n",
       "      <td>09:20</td>\n",
       "      <td>MALAGA-COSTA DEL SOL</td>\n",
       "      <td>AGP</td>\n",
       "      <td>3</td>\n",
       "      <td>El vuelo ha despegado a las 09:14</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>MELILLA</td>\n",
       "      <td>MLN</td>\n",
       "      <td>T</td>\n",
       "      <td>Llegada prevista a las 09:50</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>Nubosidad variable</td>\n",
       "      <td>SLL</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-14 09:29:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14349</th>\n",
       "      <td>AEA6006</td>\n",
       "      <td>BOEING 737-800 WINGLETS</td>\n",
       "      <td>14/04/18</td>\n",
       "      <td>07:00</td>\n",
       "      <td>PALMA DE MALLORCA</td>\n",
       "      <td>PMI</td>\n",
       "      <td>N</td>\n",
       "      <td>El vuelo ha despegado a las 07:00</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>BARCELONA-EL PRAT</td>\n",
       "      <td>BCN</td>\n",
       "      <td>T1</td>\n",
       "      <td>Llegada prevista a las 07:41</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>Lluvia</td>\n",
       "      <td>T1_G</td>\n",
       "      <td>03</td>\n",
       "      <td>2018-04-14 07:26:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14271</th>\n",
       "      <td>AEA6006</td>\n",
       "      <td>BOEING 737-800 WINGLETS</td>\n",
       "      <td>14/04/18</td>\n",
       "      <td>07:00</td>\n",
       "      <td>PALMA DE MALLORCA</td>\n",
       "      <td>PMI</td>\n",
       "      <td>N</td>\n",
       "      <td>El vuelo ha despegado a las 07:00</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>BARCELONA-EL PRAT</td>\n",
       "      <td>BCN</td>\n",
       "      <td>T1</td>\n",
       "      <td>Llegada prevista a las 07:41</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>Lluvia</td>\n",
       "      <td>T1_G</td>\n",
       "      <td>03</td>\n",
       "      <td>2018-04-14 07:26:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18253</th>\n",
       "      <td>EVE1123</td>\n",
       "      <td>32A</td>\n",
       "      <td>14/04/18</td>\n",
       "      <td>12:50</td>\n",
       "      <td>ALICANTE-ELCHE</td>\n",
       "      <td>ALC</td>\n",
       "      <td>N</td>\n",
       "      <td>El vuelo ha despegado a las 12:57</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>VIGO</td>\n",
       "      <td>VGO</td>\n",
       "      <td>1</td>\n",
       "      <td>Llegada prevista a las 14:30</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>Nubosidad variable</td>\n",
       "      <td>S1</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-04-14 13:34:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18178</th>\n",
       "      <td>EVE1123</td>\n",
       "      <td>32A</td>\n",
       "      <td>14/04/18</td>\n",
       "      <td>12:50</td>\n",
       "      <td>ALICANTE-ELCHE</td>\n",
       "      <td>ALC</td>\n",
       "      <td>N</td>\n",
       "      <td>El vuelo ha despegado a las 12:57</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>VIGO</td>\n",
       "      <td>VGO</td>\n",
       "      <td>1</td>\n",
       "      <td>Llegada prevista a las 14:30</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>Nubosidad variable</td>\n",
       "      <td>S1</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-04-14 13:34:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      flightNumber                     plane  dep_date dep_time  \\\n",
       "15589      AEA5001                    ATR-72  14/04/18    09:20   \n",
       "15722      AEA5001                    ATR-72  14/04/18    09:20   \n",
       "14349      AEA6006   BOEING 737-800 WINGLETS  14/04/18    07:00   \n",
       "14271      AEA6006   BOEING 737-800 WINGLETS  14/04/18    07:00   \n",
       "18253      EVE1123                       32A  14/04/18    12:50   \n",
       "18178      EVE1123                       32A  14/04/18    12:50   \n",
       "\n",
       "           dep_airport_name dep_airport_code dep_terminal  \\\n",
       "15589  MALAGA-COSTA DEL SOL              AGP            3   \n",
       "15722  MALAGA-COSTA DEL SOL              AGP            3   \n",
       "14349     PALMA DE MALLORCA              PMI            N   \n",
       "14271     PALMA DE MALLORCA              PMI            N   \n",
       "18253        ALICANTE-ELCHE              ALC            N   \n",
       "18178        ALICANTE-ELCHE              ALC            N   \n",
       "\n",
       "                              dep_status dep_weather_min dep_weather_max  ...  \\\n",
       "15589  El vuelo ha despegado a las 09:14              11              21  ...   \n",
       "15722  El vuelo ha despegado a las 09:14              11              21  ...   \n",
       "14349  El vuelo ha despegado a las 07:00              11              15  ...   \n",
       "14271  El vuelo ha despegado a las 07:00              11              15  ...   \n",
       "18253  El vuelo ha despegado a las 12:57              10              22  ...   \n",
       "18178  El vuelo ha despegado a las 12:57              10              22  ...   \n",
       "\n",
       "        arr_airport_name arr_airport_code arr_terminal  \\\n",
       "15589            MELILLA              MLN            T   \n",
       "15722            MELILLA              MLN            T   \n",
       "14349  BARCELONA-EL PRAT              BCN           T1   \n",
       "14271  BARCELONA-EL PRAT              BCN           T1   \n",
       "18253               VIGO              VGO            1   \n",
       "18178               VIGO              VGO            1   \n",
       "\n",
       "                         arr_status arr_weather_min arr_weather_max  \\\n",
       "15589  Llegada prevista a las 09:50              12              19   \n",
       "15722  Llegada prevista a las 09:50              12              19   \n",
       "14349  Llegada prevista a las 07:41              13              17   \n",
       "14271  Llegada prevista a las 07:41              13              17   \n",
       "18253  Llegada prevista a las 14:30               6              16   \n",
       "18178  Llegada prevista a las 14:30               6              16   \n",
       "\n",
       "         arr_weather_desc arr_room arr_belt            timestamp  \n",
       "15589  Nubosidad variable      SLL        1  2018-04-14 09:29:25  \n",
       "15722  Nubosidad variable      SLL        1  2018-04-14 09:29:25  \n",
       "14349              Lluvia     T1_G       03  2018-04-14 07:26:52  \n",
       "14271              Lluvia     T1_G       03  2018-04-14 07:26:52  \n",
       "18253  Nubosidad variable       S1        3  2018-04-14 13:34:00  \n",
       "18178  Nubosidad variable       S1        3  2018-04-14 13:34:00  \n",
       "\n",
       "[6 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Duplicados eliminados: 24 filas\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VALIDACIÓN PROBLEMA 2\n",
      "--------------------------------------------------------------------------------\n",
      "  Duplicados restantes: 0\n",
      "  ✓ VALIDACIÓN EXITOSA: No hay duplicados\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ETAPA 3: LIMPIEZA - PROBLEMA 2 (Duplicados)\n",
    "# ============================================================================\n",
    "\n",
    "def detectar_problema_2(df):\n",
    "    \"\"\"\n",
    "    Detecta filas duplicadas\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROBLEMA 2: Detección de duplicados\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    duplicados_totales = df.duplicated().sum()\n",
    "    print(f\"  Total de filas duplicadas: {duplicados_totales}\")\n",
    "    \n",
    "    if duplicados_totales > 0:\n",
    "        print(\"\\n  Ejemplos de duplicados:\")\n",
    "        display(df[df.duplicated(keep=False)].sort_values('flightNumber').head(6))\n",
    "    \n",
    "    return duplicados_totales\n",
    "\n",
    "\n",
    "def limpiar_problema_2(df):\n",
    "    \"\"\"\n",
    "    Elimina filas duplicadas manteniendo la primera ocurrencia\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    filas_antes = len(df_clean)\n",
    "    df_clean.drop_duplicates(inplace=True, keep='first')\n",
    "    filas_despues = len(df_clean)\n",
    "    \n",
    "    print(f\"\\n✓ Duplicados eliminados: {filas_antes - filas_despues} filas\")\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def validar_problema_2(df_limpio):\n",
    "    \"\"\"\n",
    "    Valida que no queden duplicados\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"VALIDACIÓN PROBLEMA 2\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    duplicados = df_limpio.duplicated().sum()\n",
    "    print(f\"  Duplicados restantes: {duplicados}\")\n",
    "    \n",
    "    if duplicados == 0:\n",
    "        print(\"  ✓ VALIDACIÓN EXITOSA: No hay duplicados\")\n",
    "    else:\n",
    "        print(\"  ✗ VALIDACIÓN FALLIDA: Aún hay duplicados\")\n",
    "    \n",
    "    return duplicados == 0\n",
    "\n",
    "\n",
    "# Ejecutar limpieza Problema 2\n",
    "detectar_problema_2(df_step1)\n",
    "df_step2 = limpiar_problema_2(df_step1)\n",
    "validar_problema_2(df_step2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad475f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROBLEMA 3: Detección de códigos de aeropuerto inconsistentes\n",
      "================================================================================\n",
      "\n",
      "✓ Códigos de aeropuerto normalizados a 3 caracteres en mayúsculas\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VALIDACIÓN PROBLEMA 3\n",
      "--------------------------------------------------------------------------------\n",
      "  dep_airport_code: 0 códigos con longitud != 3\n",
      "  arr_airport_code: 0 códigos con longitud != 3\n",
      "  ✓ VALIDACIÓN EXITOSA: Todos los códigos tienen 3 caracteres\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ETAPA 4: LIMPIEZA - PROBLEMA 3 (Inconsistencias en códigos de aeropuerto)\n",
    "# ============================================================================\n",
    "\n",
    "def detectar_problema_3(df):\n",
    "    \"\"\"\n",
    "    Detecta códigos de aeropuerto con longitud incorrecta\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROBLEMA 3: Detección de códigos de aeropuerto inconsistentes\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    problemas = {}\n",
    "    \n",
    "    for col in ['dep_airport_code', 'arr_airport_code']:\n",
    "        if col in df.columns:\n",
    "            longitudes = df[col].dropna().str.len()\n",
    "            incorrectos = (longitudes != 3).sum()\n",
    "            \n",
    "            if incorrectos > 0:\n",
    "                problemas[col] = incorrectos\n",
    "                print(f\"\\n  Columna: {col}\")\n",
    "                print(f\"    - Códigos con longitud != 3: {incorrectos}\")\n",
    "                print(f\"    - Ejemplos:\")\n",
    "                ejemplos = df[df[col].str.len() != 3][col].unique()[:5]\n",
    "                for ej in ejemplos:\n",
    "                    print(f\"      '{ej}' (longitud: {len(ej)})\")\n",
    "    \n",
    "    return problemas\n",
    "\n",
    "\n",
    "def limpiar_problema_3(df):\n",
    "    \"\"\"\n",
    "    Normaliza códigos de aeropuerto a 3 caracteres en mayúsculas\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    for col in ['dep_airport_code', 'arr_airport_code']:\n",
    "        if col in df_clean.columns:\n",
    "            # Convertir a mayúsculas y eliminar espacios\n",
    "            df_clean[col] = df_clean[col].str.strip().str.upper()\n",
    "            \n",
    "            # Truncar o rellenar a 3 caracteres (ajustar según necesidad)\n",
    "            # Aquí asumimos que códigos con longitud != 3 son errores y se marcan como nulos\n",
    "            mask = df_clean[col].str.len() != 3\n",
    "            df_clean.loc[mask, col] = np.nan\n",
    "    \n",
    "    print(\"\\n✓ Códigos de aeropuerto normalizados a 3 caracteres en mayúsculas\")\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def validar_problema_3(df_limpio):\n",
    "    \"\"\"\n",
    "    Valida que todos los códigos tengan 3 caracteres\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"VALIDACIÓN PROBLEMA 3\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    todo_ok = True\n",
    "    \n",
    "    for col in ['dep_airport_code', 'arr_airport_code']:\n",
    "        if col in df_limpio.columns:\n",
    "            longitudes = df_limpio[col].dropna().str.len()\n",
    "            incorrectos = (longitudes != 3).sum()\n",
    "            print(f\"  {col}: {incorrectos} códigos con longitud != 3\")\n",
    "            \n",
    "            if incorrectos > 0:\n",
    "                todo_ok = False\n",
    "    \n",
    "    if todo_ok:\n",
    "        print(\"  ✓ VALIDACIÓN EXITOSA: Todos los códigos tienen 3 caracteres\")\n",
    "    else:\n",
    "        print(\"  ✗ VALIDACIÓN FALLIDA: Aún hay códigos incorrectos\")\n",
    "    \n",
    "    return todo_ok\n",
    "\n",
    "\n",
    "# Ejecutar limpieza Problema 3\n",
    "detectar_problema_3(df_step2)\n",
    "df_step3 = limpiar_problema_3(df_step2)\n",
    "validar_problema_3(df_step3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b213ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROBLEMA 4: Detección de inconsistencias en nombres de aeropuerto\n",
      "================================================================================\n",
      "\n",
      "  Códigos de salida con múltiples nombres: 0\n",
      "\n",
      "  Códigos de llegada con múltiples nombres: 0\n",
      "\n",
      "✓ Nombres de aeropuertos normalizados según código\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VALIDACIÓN PROBLEMA 4\n",
      "--------------------------------------------------------------------------------\n",
      "  Códigos de salida con múltiples nombres: 0\n",
      "  Códigos de llegada con múltiples nombres: 0\n",
      "  ✓ VALIDACIÓN EXITOSA: Cada código tiene un único nombre\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ETAPA 5: LIMPIEZA - PROBLEMA 4 (Inconsistencias en nombres de aeropuerto)\n",
    "# ============================================================================\n",
    "\n",
    "def detectar_problema_4(df):\n",
    "    \"\"\"\n",
    "    Detecta inconsistencias en nombres de aeropuertos para el mismo código\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROBLEMA 4: Detección de inconsistencias en nombres de aeropuerto\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Analizar salidas\n",
    "    dep_mapping = df.groupby('dep_airport_code')['dep_airport_name'].unique()\n",
    "    dep_inconsistentes = {k: v for k, v in dep_mapping.items() if len(v) > 1}\n",
    "    \n",
    "    # Analizar llegadas\n",
    "    arr_mapping = df.groupby('arr_airport_code')['arr_airport_name'].unique()\n",
    "    arr_inconsistentes = {k: v for k, v in arr_mapping.items() if len(v) > 1}\n",
    "    \n",
    "    print(f\"\\n  Códigos de salida con múltiples nombres: {len(dep_inconsistentes)}\")\n",
    "    for code, names in list(dep_inconsistentes.items())[:3]:\n",
    "        print(f\"    {code}: {names}\")\n",
    "    \n",
    "    print(f\"\\n  Códigos de llegada con múltiples nombres: {len(arr_inconsistentes)}\")\n",
    "    for code, names in list(arr_inconsistentes.items())[:3]:\n",
    "        print(f\"    {code}: {names}\")\n",
    "    \n",
    "    return dep_inconsistentes, arr_inconsistentes\n",
    "\n",
    "\n",
    "def limpiar_problema_4(df):\n",
    "    \"\"\"\n",
    "    Normaliza nombres de aeropuertos usando el nombre más frecuente por código\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Crear mapeo código -> nombre más frecuente (salidas)\n",
    "    dep_map = df_clean.groupby('dep_airport_code')['dep_airport_name'].agg(\n",
    "        lambda x: x.value_counts().index[0] if len(x) > 0 else np.nan\n",
    "    ).to_dict()\n",
    "    \n",
    "    # Crear mapeo código -> nombre más frecuente (llegadas)\n",
    "    arr_map = df_clean.groupby('arr_airport_code')['arr_airport_name'].agg(\n",
    "        lambda x: x.value_counts().index[0] if len(x) > 0 else np.nan\n",
    "    ).to_dict()\n",
    "    \n",
    "    # Aplicar mapeos\n",
    "    df_clean['dep_airport_name'] = df_clean['dep_airport_code'].map(dep_map)\n",
    "    df_clean['arr_airport_name'] = df_clean['arr_airport_code'].map(arr_map)\n",
    "    \n",
    "    print(\"\\n✓ Nombres de aeropuertos normalizados según código\")\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def validar_problema_4(df_limpio):\n",
    "    \"\"\"\n",
    "    Valida que cada código tenga un único nombre\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"VALIDACIÓN PROBLEMA 4\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    dep_mapping = df_limpio.groupby('dep_airport_code')['dep_airport_name'].nunique()\n",
    "    arr_mapping = df_limpio.groupby('arr_airport_code')['arr_airport_name'].nunique()\n",
    "    \n",
    "    dep_inconsistentes = (dep_mapping > 1).sum()\n",
    "    arr_inconsistentes = (arr_mapping > 1).sum()\n",
    "    \n",
    "    print(f\"  Códigos de salida con múltiples nombres: {dep_inconsistentes}\")\n",
    "    print(f\"  Códigos de llegada con múltiples nombres: {arr_inconsistentes}\")\n",
    "    \n",
    "    if dep_inconsistentes == 0 and arr_inconsistentes == 0:\n",
    "        print(\"  ✓ VALIDACIÓN EXITOSA: Cada código tiene un único nombre\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"  ✗ VALIDACIÓN FALLIDA: Aún hay inconsistencias\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Ejecutar limpieza Problema 4\n",
    "detectar_problema_4(df_step3)\n",
    "df_step4 = limpiar_problema_4(df_step3)\n",
    "validar_problema_4(df_step4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d949b586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROBLEMA 5: Detección de formatos de fecha/hora inconsistentes\n",
      "================================================================================\n",
      "\n",
      "  Ejemplos de fechas y horas actuales:\n",
      "    dep_date: ['13/04/18', '13/04/18', '13/04/18']\n",
      "    dep_time: ['10:00', '14:15', '15:05']\n",
      "    arr_date: ['13/04/18', '13/04/18', '13/04/18']\n",
      "    arr_time: ['10:10', '14:30', '15:15']\n",
      "\n",
      "  Problema: Fechas en formato DD/MM/YY y horas separadas\n",
      "  Solución: Unificar en datetime ISO 8601 (YYYY-MM-DDTHH:MM:SS)\n",
      "\n",
      "✓ Fechas y horas convertidas a formato ISO 8601\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VALIDACIÓN PROBLEMA 5\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Ejemplos de datetime unificados:\n",
      "    dep_datetime_scheduled: ['2018-04-13T10:00:00', '2018-04-13T14:15:00', '2018-04-13T15:05:00']\n",
      "    arr_datetime_scheduled: ['2018-04-13T10:10:00', '2018-04-13T14:30:00', '2018-04-13T15:15:00']\n",
      "  ✓ VALIDACIÓN EXITOSA: Todas las fechas en formato ISO 8601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ETAPA 6: LIMPIEZA - PROBLEMA 5 (Formatos de fecha y hora inconsistentes)\n",
    "# ============================================================================\n",
    "\n",
    "def detectar_problema_5(df):\n",
    "    \"\"\"\n",
    "    Detecta problemas en formatos de fecha y hora\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROBLEMA 5: Detección de formatos de fecha/hora inconsistentes\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n  Ejemplos de fechas y horas actuales:\")\n",
    "    print(f\"    dep_date: {df['dep_date'].head(3).tolist()}\")\n",
    "    print(f\"    dep_time: {df['dep_time'].head(3).tolist()}\")\n",
    "    print(f\"    arr_date: {df['arr_date'].head(3).tolist()}\")\n",
    "    print(f\"    arr_time: {df['arr_time'].head(3).tolist()}\")\n",
    "    \n",
    "    print(\"\\n  Problema: Fechas en formato DD/MM/YY y horas separadas\")\n",
    "    print(\"  Solución: Unificar en datetime ISO 8601 (YYYY-MM-DDTHH:MM:SS)\")\n",
    "\n",
    "\n",
    "def limpiar_problema_5(df):\n",
    "    \"\"\"\n",
    "    Convierte fechas y horas a formato ISO 8601\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Función auxiliar para combinar fecha y hora\n",
    "    def combinar_fecha_hora(fecha, hora):\n",
    "        try:\n",
    "            # Parsear fecha DD/MM/YY\n",
    "            fecha_obj = pd.to_datetime(fecha, format='%d/%m/%y', errors='coerce')\n",
    "            \n",
    "            # Combinar con hora\n",
    "            if pd.notna(fecha_obj) and pd.notna(hora):\n",
    "                datetime_str = f\"{fecha_obj.strftime('%Y-%m-%d')}T{hora}:00\"\n",
    "                return datetime_str\n",
    "            else:\n",
    "                return None\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    # Crear campos datetime unificados\n",
    "    df_clean['dep_datetime_scheduled'] = df_clean.apply(\n",
    "        lambda row: combinar_fecha_hora(row['dep_date'], row['dep_time']), axis=1\n",
    "    )\n",
    "    \n",
    "    df_clean['arr_datetime_scheduled'] = df_clean.apply(\n",
    "        lambda row: combinar_fecha_hora(row['arr_date'], row['arr_time']), axis=1\n",
    "    )\n",
    "    \n",
    "    # Convertir timestamp de ingesta\n",
    "    df_clean['ingestion_timestamp'] = pd.to_datetime(\n",
    "        df_clean['timestamp'], errors='coerce'\n",
    "    ).dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    \n",
    "    print(\"\\n✓ Fechas y horas convertidas a formato ISO 8601\")\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def validar_problema_5(df_limpio):\n",
    "    \"\"\"\n",
    "    Valida que las fechas estén en formato ISO 8601\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"VALIDACIÓN PROBLEMA 5\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    print(\"\\n  Ejemplos de datetime unificados:\")\n",
    "    print(f\"    dep_datetime_scheduled: {df_limpio['dep_datetime_scheduled'].head(3).tolist()}\")\n",
    "    print(f\"    arr_datetime_scheduled: {df_limpio['arr_datetime_scheduled'].head(3).tolist()}\")\n",
    "    \n",
    "    # Validar formato ISO 8601\n",
    "    patron_iso = r'^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}$'\n",
    "    \n",
    "    dep_validos = df_limpio['dep_datetime_scheduled'].dropna().str.match(patron_iso).all()\n",
    "    arr_validos = df_limpio['arr_datetime_scheduled'].dropna().str.match(patron_iso).all()\n",
    "    \n",
    "    if dep_validos and arr_validos:\n",
    "        print(\"  ✓ VALIDACIÓN EXITOSA: Todas las fechas en formato ISO 8601\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"  ✗ VALIDACIÓN FALLIDA: Hay fechas con formato incorrecto\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Ejecutar limpieza Problema 5\n",
    "detectar_problema_5(df_step4)\n",
    "df_step5 = limpiar_problema_5(df_step4)\n",
    "validar_problema_5(df_step5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fecffcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROBLEMA 6: Detección de estados de vuelo no estructurados\n",
      "================================================================================\n",
      "\n",
      "  Ejemplos de dep_status:\n",
      "dep_status\n",
      "Salida prevista a las 07:00    546\n",
      "Salida prevista a las 16:00    397\n",
      "Salida prevista a las 07:30    388\n",
      "Salida prevista a las 08:00    358\n",
      "Salida prevista a las 10:30    318\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  Ejemplos de arr_status:\n",
      "arr_status\n",
      "Llegada prevista a las 08:30    328\n",
      "Llegada prevista a las 17:30    266\n",
      "Llegada prevista a las 15:30    245\n",
      "Llegada prevista a las 10:10    240\n",
      "Llegada prevista a las 09:00    231\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  Problema: Estados en texto libre sin categorización\n",
      "  Solución: Extraer código de estado normalizado\n",
      "\n",
      "✓ Códigos de estado extraídos y datetime_actual generados\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "VALIDACIÓN PROBLEMA 6\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  Distribución de dep_status_code:\n",
      "dep_status_code\n",
      "PROGRAMADO     25317\n",
      "DESPEGADO      12582\n",
      "DESCONOCIDO      868\n",
      "OTRO             230\n",
      "CANCELADO         52\n",
      "ATERRIZADO        29\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  Distribución de arr_status_code:\n",
      "arr_status_code\n",
      "PROGRAMADO     20895\n",
      "DESCONOCIDO    12927\n",
      "ATERRIZADO      5011\n",
      "OTRO             204\n",
      "CANCELADO         22\n",
      "DESPEGADO         19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  ✓ VALIDACIÓN EXITOSA: Todos los códigos son válidos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ETAPA 7: LIMPIEZA - PROBLEMA 6 (Estados de vuelo no estructurados)\n",
    "# ============================================================================\n",
    "\n",
    "def detectar_problema_6(df):\n",
    "    \"\"\"\n",
    "    Detecta estados de vuelo en texto libre\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROBLEMA 6: Detección de estados de vuelo no estructurados\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n  Ejemplos de dep_status:\")\n",
    "    print(df['dep_status'].value_counts().head(5))\n",
    "    \n",
    "    print(\"\\n  Ejemplos de arr_status:\")\n",
    "    print(df['arr_status'].value_counts().head(5))\n",
    "    \n",
    "    print(\"\\n  Problema: Estados en texto libre sin categorización\")\n",
    "    print(\"  Solución: Extraer código de estado normalizado\")\n",
    "\n",
    "\n",
    "def limpiar_problema_6(df):\n",
    "    \"\"\"\n",
    "    Extrae códigos de estado normalizados y datetime_actual de los textos de estado\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Función para extraer código de estado\n",
    "    def extraer_status_code(texto):\n",
    "        if pd.isna(texto):\n",
    "            return 'DESCONOCIDO'\n",
    "        \n",
    "        texto_lower = texto.lower()\n",
    "        \n",
    "        if 'despegado' in texto_lower or 'ha despegado' in texto_lower:\n",
    "            return 'DESPEGADO'\n",
    "        elif 'aterrizado' in texto_lower or 'ha aterrizado' in texto_lower:\n",
    "            return 'ATERRIZADO'\n",
    "        elif 'cancelado' in texto_lower or 'cancelada' in texto_lower:\n",
    "            return 'CANCELADO'\n",
    "        elif 'retrasado' in texto_lower or 'retraso' in texto_lower:\n",
    "            return 'RETRASADO'\n",
    "        elif 'prevista' in texto_lower or 'previsto' in texto_lower:\n",
    "            return 'PROGRAMADO'\n",
    "        else:\n",
    "            return 'OTRO'\n",
    "    \n",
    "    # Función para extraer hora actual del texto de estado\n",
    "    def extraer_hora_actual(texto, fecha_base):\n",
    "        if pd.isna(texto):\n",
    "            return None\n",
    "        \n",
    "        # Buscar patrón \"a las HH:MM\"\n",
    "        match = re.search(r'a las (\\d{1,2}):(\\d{2})', texto)\n",
    "        if match and pd.notna(fecha_base):\n",
    "            hora = match.group(1).zfill(2)\n",
    "            minuto = match.group(2)\n",
    "            # Extraer solo la fecha de fecha_base\n",
    "            fecha_parte = fecha_base.split('T')[0]\n",
    "            return f\"{fecha_parte}T{hora}:{minuto}:00\"\n",
    "        return None\n",
    "    \n",
    "    # Aplicar extracciones\n",
    "    df_clean['dep_status_code'] = df_clean['dep_status'].apply(extraer_status_code)\n",
    "    df_clean['arr_status_code'] = df_clean['arr_status'].apply(extraer_status_code)\n",
    "    \n",
    "    df_clean['dep_datetime_actual'] = df_clean.apply(\n",
    "        lambda row: extraer_hora_actual(row['dep_status'], row['dep_datetime_scheduled']),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    df_clean['arr_datetime_actual'] = df_clean.apply(\n",
    "        lambda row: extraer_hora_actual(row['arr_status'], row['arr_datetime_scheduled']),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✓ Códigos de estado extraídos y datetime_actual generados\")\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def validar_problema_6(df_limpio):\n",
    "    \"\"\"\n",
    "    Valida que los códigos de estado sean válidos\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"VALIDACIÓN PROBLEMA 6\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    codigos_validos = {'PROGRAMADO', 'DESPEGADO', 'ATERRIZADO', 'CANCELADO', 'RETRASADO', 'OTRO', 'DESCONOCIDO'}\n",
    "    \n",
    "    print(\"\\n  Distribución de dep_status_code:\")\n",
    "    print(df_limpio['dep_status_code'].value_counts())\n",
    "    \n",
    "    print(\"\\n  Distribución de arr_status_code:\")\n",
    "    print(df_limpio['arr_status_code'].value_counts())\n",
    "    \n",
    "    dep_invalidos = ~df_limpio['dep_status_code'].isin(codigos_validos)\n",
    "    arr_invalidos = ~df_limpio['arr_status_code'].isin(codigos_validos)\n",
    "    \n",
    "    if not dep_invalidos.any() and not arr_invalidos.any():\n",
    "        print(\"\\n  ✓ VALIDACIÓN EXITOSA: Todos los códigos son válidos\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"\\n  ✗ VALIDACIÓN FALLIDA: Hay códigos inválidos\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Ejecutar limpieza Problema 6\n",
    "detectar_problema_6(df_step5)\n",
    "df_step6 = limpiar_problema_6(df_step5)\n",
    "validar_problema_6(df_step6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01ef9f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LIMPIEZAS ADICIONALES\n",
      "================================================================================\n",
      "\n",
      "1. Normalizando nombres de columnas...\n",
      "2. Convirtiendo temperaturas a tipo numérico...\n",
      "3. Eliminando espacios en blanco innecesarios...\n",
      "4. Validando integridad de flightNumber...\n",
      "\n",
      "✓ Limpiezas adicionales completadas\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ETAPA 8: LIMPIEZAS ADICIONALES (Completitud y consistencia)\n",
    "# ============================================================================\n",
    "\n",
    "def limpiezas_adicionales(df):\n",
    "    \"\"\"\n",
    "    Aplica limpiezas adicionales para mejorar calidad\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LIMPIEZAS ADICIONALES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # 1. Normalizar nombres de columnas\n",
    "    print(\"\\n1. Normalizando nombres de columnas...\")\n",
    "    # (Ya están bien, pero se podría hacer snake_case completo)\n",
    "    \n",
    "    # 2. Convertir temperaturas a numérico\n",
    "    print(\"2. Convirtiendo temperaturas a tipo numérico...\")\n",
    "    for col in ['dep_weather_min', 'dep_weather_max', 'arr_weather_min', 'arr_weather_max']:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "    \n",
    "    # 3. Eliminar espacios en blanco de strings\n",
    "    print(\"3. Eliminando espacios en blanco innecesarios...\")\n",
    "    string_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "    for col in string_cols:\n",
    "        df_clean[col] = df_clean[col].str.strip() if df_clean[col].dtype == 'object' else df_clean[col]\n",
    "    \n",
    "    # 4. Validar que flightNumber no sea nulo\n",
    "    print(\"4. Validando integridad de flightNumber...\")\n",
    "    nulos_flight = df_clean['flightNumber'].isna().sum()\n",
    "    if nulos_flight > 0:\n",
    "        print(f\"   ⚠ Advertencia: {nulos_flight} filas sin flightNumber (se eliminarán)\")\n",
    "        df_clean = df_clean[df_clean['flightNumber'].notna()]\n",
    "    \n",
    "    print(\"\\n✓ Limpiezas adicionales completadas\")\n",
    "    return df_clean\n",
    "\n",
    "def normalizar_nulos(df):\n",
    "    \"\"\"\n",
    "    Reemplaza NaN y valores '-' que significan 'sin dato' por None,\n",
    "    para que el resultante use 'null' correctamente.\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Columnas donde '-' significa 'sin dato'\n",
    "    columnas_guion_a_null = [\n",
    "        'dep_terminal', 'dep_counter', 'dep_door',\n",
    "        'arr_terminal', 'arr_room', 'arr_belt'\n",
    "    ]\n",
    "    \n",
    "    for col in columnas_guion_a_null:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = df_clean[col].replace('-', np.nan)\n",
    "    \n",
    "    # (Opcional) si quieres, puedes aplicar esto a otras columnas de texto\n",
    "    # donde '-' NO es un valor real\n",
    "    return df_clean\n",
    "\n",
    "# Ejecutar limpiezas adicionales\n",
    "df_final = limpiezas_adicionales(df_step6)\n",
    "df_final = normalizar_nulos(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f9e65dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RESUMEN FINAL DE CALIDAD DE DATOS\n",
      "================================================================================\n",
      "\n",
      "1. Dimensiones:\n",
      "   Original: 39102 filas × 25 columnas\n",
      "   Final:    39078 filas × 32 columnas\n",
      "   Filas eliminadas: 24\n",
      "\n",
      "2. Valores nulos:\n",
      "   Original: 0 nulos\n",
      "   Final:    180178 nulos\n",
      "\n",
      "3. Duplicados:\n",
      "   Original: 24\n",
      "   Final:    0\n",
      "\n",
      "4. Nuevas columnas creadas:\n",
      "   - arr_status_code\n",
      "   - arr_datetime_scheduled\n",
      "   - dep_status_code\n",
      "   - arr_datetime_actual\n",
      "   - ingestion_timestamp\n",
      "   - dep_datetime_actual\n",
      "   - dep_datetime_scheduled\n",
      "\n",
      "✓ Dataset limpio y listo para exportación\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ETAPA 9: RESUMEN FINAL DE CALIDAD\n",
    "# ============================================================================\n",
    "\n",
    "def generar_resumen_calidad(df_original, df_final):\n",
    "    \"\"\"\n",
    "    Genera un resumen comparativo de la calidad de datos\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESUMEN FINAL DE CALIDAD DE DATOS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\n1. Dimensiones:\")\n",
    "    print(f\"   Original: {df_original.shape[0]} filas × {df_original.shape[1]} columnas\")\n",
    "    print(f\"   Final:    {df_final.shape[0]} filas × {df_final.shape[1]} columnas\")\n",
    "    print(f\"   Filas eliminadas: {df_original.shape[0] - df_final.shape[0]}\")\n",
    "    \n",
    "    print(f\"\\n2. Valores nulos:\")\n",
    "    print(f\"   Original: {df_original.isnull().sum().sum()} nulos\")\n",
    "    print(f\"   Final:    {df_final.isnull().sum().sum()} nulos\")\n",
    "    \n",
    "    print(f\"\\n3. Duplicados:\")\n",
    "    print(f\"   Original: {df_original.duplicated().sum()}\")\n",
    "    print(f\"   Final:    {df_final.duplicated().sum()}\")\n",
    "    \n",
    "    print(f\"\\n4. Nuevas columnas creadas:\")\n",
    "    nuevas_cols = set(df_final.columns) - set(df_original.columns)\n",
    "    for col in nuevas_cols:\n",
    "        print(f\"   - {col}\")\n",
    "    \n",
    "    print(\"\\n✓ Dataset limpio y listo para exportación\")\n",
    "\n",
    "\n",
    "# Generar resumen\n",
    "generar_resumen_calidad(df_raw, df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1800b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ETAPA 10: EXPORTACIÓN A JSON\n",
    "# ============================================================================\n",
    "\n",
    "def safe_value(v):\n",
    "    \"\"\"\n",
    "    Convierte valores NaN de pandas a None (que será null en JSON).\n",
    "    Deja el resto tal cual.\n",
    "    \"\"\"\n",
    "    if pd.isna(v):\n",
    "        return None\n",
    "    return v\n",
    "\n",
    "\n",
    "def transformar_a_json_estructura(df):\n",
    "    \"\"\"\n",
    "    Transforma el DataFrame limpio a la estructura JSON propuesta\n",
    "    \n",
    "    Returns:\n",
    "        Lista de diccionarios con la estructura JSON de vuelos\n",
    "    \"\"\"\n",
    "    vuelos_json = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        vuelo = {\n",
    "            \"flight_number\": safe_value(row.get('flightNumber')),\n",
    "            \"plane\": safe_value(row.get('plane')),\n",
    "            \"departure\": {\n",
    "                \"airport_name\": safe_value(row.get('dep_airport_name')),\n",
    "                \"airport_code\": safe_value(row.get('dep_airport_code')),\n",
    "                \"terminal\": safe_value(row.get('dep_terminal')),\n",
    "                \"counter\": safe_value(row.get('dep_counter')),\n",
    "                \"gate\": safe_value(row.get('dep_door')),\n",
    "                \"datetime_scheduled\": safe_value(row.get('dep_datetime_scheduled')),\n",
    "                \"datetime_actual\": safe_value(row.get('dep_datetime_actual')),\n",
    "                \"status_code\": safe_value(row.get('dep_status_code')),\n",
    "                \"status_text\": safe_value(row.get('dep_status'))\n",
    "            },\n",
    "            \"arrival\": {\n",
    "                \"airport_name\": safe_value(row.get('arr_airport_name')),\n",
    "                \"airport_code\": safe_value(row.get('arr_airport_code')),\n",
    "                \"terminal\": safe_value(row.get('arr_terminal')),\n",
    "                \"room\": safe_value(row.get('arr_room')),\n",
    "                \"belt\": safe_value(row.get('arr_belt')),\n",
    "                \"datetime_scheduled\": safe_value(row.get('arr_datetime_scheduled')),\n",
    "                \"datetime_actual\": safe_value(row.get('arr_datetime_actual')),\n",
    "                \"status_code\": safe_value(row.get('arr_status_code')),\n",
    "                \"status_text\": safe_value(row.get('arr_status'))\n",
    "            },\n",
    "            \"weather\": {\n",
    "                \"departure\": {\n",
    "                    \"temp_min\": safe_value(row.get('dep_weather_min')),\n",
    "                    \"temp_max\": safe_value(row.get('dep_weather_max')),\n",
    "                    \"description\": safe_value(row.get('dep_weather_desc'))\n",
    "                },\n",
    "                \"arrival\": {\n",
    "                    \"temp_min\": safe_value(row.get('arr_weather_min')),\n",
    "                    \"temp_max\": safe_value(row.get('arr_weather_max')),\n",
    "                    \"description\": safe_value(row.get('arr_weather_desc'))\n",
    "                }\n",
    "            },\n",
    "            \"ingestion_timestamp\": safe_value(row.get('ingestion_timestamp'))\n",
    "        }\n",
    "        \n",
    "        vuelos_json.append(vuelo)\n",
    "    \n",
    "    return vuelos_json\n",
    "\n",
    "\n",
    "def exportar_json(vuelos_json, ruta_salida='vuelos_limpio.json', num_documentos=None, indent=2):\n",
    "    \"\"\"\n",
    "    Exporta la lista de vuelos a un archivo JSON\n",
    "    \n",
    "    Args:\n",
    "        vuelos_json: lista de diccionarios con estructura de vuelos\n",
    "        ruta_salida: ruta del archivo JSON de salida\n",
    "        num_documentos: número de documentos a exportar. Si es None, exporta todos.\n",
    "        indent: nivel de indentación para legibilidad\n",
    "    \"\"\"\n",
    "    # Determinar cuántos documentos exportar\n",
    "    if num_documentos is None:\n",
    "        documentos_a_exportar = vuelos_json\n",
    "        total_exportado = len(vuelos_json)\n",
    "    else:\n",
    "        documentos_a_exportar = vuelos_json[:num_documentos]\n",
    "        total_exportado = min(num_documentos, len(vuelos_json))\n",
    "    \n",
    "    # Exportar a JSON\n",
    "    with open(ruta_salida, 'w', encoding='utf-8') as f:\n",
    "        json.dump(documentos_a_exportar, f, ensure_ascii=False, indent=indent)\n",
    "    \n",
    "    print(f\"\\n✓ Archivo JSON exportado: {ruta_salida}\")\n",
    "    print(f\"  Total de vuelos exportados: {total_exportado}\")\n",
    "    print(f\"  Total de vuelos disponibles: {len(vuelos_json)}\")\n",
    "    \n",
    "    if num_documentos and num_documentos < len(vuelos_json):\n",
    "        print(f\"  ⚠ Se exportaron solo los primeros {num_documentos} documentos\")\n",
    "    \n",
    "    tamanio_kb = round(len(json.dumps(documentos_a_exportar)) / 1024, 2)\n",
    "    print(f\"  Tamaño del archivo: {tamanio_kb} KB\")\n",
    "\n",
    "\n",
    "# Ejecutar transformación y exportación\n",
    "vuelos_json = transformar_a_json_estructura(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c30ee93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Archivo JSON exportado: dataset3_vuelos_100.json\n",
      "  Total de vuelos exportados: 100\n",
      "  Total de vuelos disponibles: 39078\n",
      "  ⚠ Se exportaron solo los primeros 100 documentos\n",
      "  Tamaño del archivo: 80.44 KB\n"
     ]
    }
   ],
   "source": [
    "# 1. Exportar TODOS los documentos (comportamiento por defecto)\n",
    "#exportar_json(vuelos_json, ruta_salida='dataset3_vuelos_completo.json')\n",
    "\n",
    "# 2. Exportar solo los primeros 10 documentos (para pruebas)\n",
    "#exportar_json(vuelos_json, ruta_salida='dataset3_vuelos_muestra.json', num_documentos=10)\n",
    "\n",
    "# 3. Exportar los primeros 100 documentos\n",
    "exportar_json(vuelos_json, ruta_salida='dataset3_vuelos_100.json', num_documentos=100)\n",
    "\n",
    "# 4. Exportar 1 solo documento (para validación rápida)\n",
    "#exportar_json(vuelos_json, ruta_salida='dataset3_vuelos_ejemplo.json', num_documentos=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2c39b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROCESO COMPLETADO EXITOSAMENTE\n",
      "================================================================================\n",
      "\n",
      "Archivo generado: dataset3_vuelos_limpio.json\n",
      "El dataset está listo para la entrega.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FIN DEL NOTEBOOK\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESO COMPLETADO EXITOSAMENTE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nArchivo generado: dataset3_vuelos_limpio.json\")\n",
    "print(\"El dataset está listo para la entrega.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1da92544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flightNumber</th>\n",
       "      <th>plane</th>\n",
       "      <th>dep_date</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>dep_airport_name</th>\n",
       "      <th>dep_airport_code</th>\n",
       "      <th>dep_terminal</th>\n",
       "      <th>dep_status</th>\n",
       "      <th>dep_weather_min</th>\n",
       "      <th>dep_weather_max</th>\n",
       "      <th>...</th>\n",
       "      <th>arr_room</th>\n",
       "      <th>arr_belt</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>dep_datetime_scheduled</th>\n",
       "      <th>arr_datetime_scheduled</th>\n",
       "      <th>ingestion_timestamp</th>\n",
       "      <th>dep_status_code</th>\n",
       "      <th>arr_status_code</th>\n",
       "      <th>dep_datetime_actual</th>\n",
       "      <th>arr_datetime_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33811</th>\n",
       "      <td>IBS3927</td>\n",
       "      <td>32A</td>\n",
       "      <td>15/04/18</td>\n",
       "      <td>06:45</td>\n",
       "      <td>TENERIFE SUR</td>\n",
       "      <td>TFS</td>\n",
       "      <td>T</td>\n",
       "      <td>El vuelo ha despegado a las 06:49</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2018-04-15 12:35:49</td>\n",
       "      <td>2018-04-15T06:45:00</td>\n",
       "      <td>2018-04-15T10:30:00</td>\n",
       "      <td>2018-04-15T12:35:49</td>\n",
       "      <td>DESPEGADO</td>\n",
       "      <td>ATERRIZADO</td>\n",
       "      <td>2018-04-15T06:49:00</td>\n",
       "      <td>2018-04-15T10:34:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      flightNumber plane  dep_date dep_time dep_airport_name dep_airport_code  \\\n",
       "33811      IBS3927   32A  15/04/18    06:45     TENERIFE SUR              TFS   \n",
       "\n",
       "      dep_terminal                         dep_status  dep_weather_min  \\\n",
       "33811            T  El vuelo ha despegado a las 06:49             17.0   \n",
       "\n",
       "       dep_weather_max  ... arr_room arr_belt            timestamp  \\\n",
       "33811             23.0  ...       10       18  2018-04-15 12:35:49   \n",
       "\n",
       "      dep_datetime_scheduled arr_datetime_scheduled  ingestion_timestamp  \\\n",
       "33811    2018-04-15T06:45:00    2018-04-15T10:30:00  2018-04-15T12:35:49   \n",
       "\n",
       "      dep_status_code arr_status_code  dep_datetime_actual  \\\n",
       "33811       DESPEGADO      ATERRIZADO  2018-04-15T06:49:00   \n",
       "\n",
       "       arr_datetime_actual  \n",
       "33811  2018-04-15T10:34:00  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "03_bases_datos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
