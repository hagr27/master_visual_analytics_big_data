{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4d3850fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATASET 2: ALOJAMIENTOS TURÍSTICOS - LIMPIEZA Y GENERACIÓN JSON\n",
    "# ============================================================================\n",
    "# Actividad 1: Limpieza de datos\n",
    "# Asignatura: Bases de Datos para el Big Data\n",
    "# Dataset: alojamientos_turisticos.csv\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f12609e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATASET 2: ALOJAMIENTOS TURÍSTICOS - LIMPIEZA Y GENERACIÓN JSON\n",
    "# ============================================================================\n",
    "# Actividad 1: Limpieza de datos\n",
    "# Asignatura: Bases de Datos para el Big Data\n",
    "# Dataset: alojamientos_turisticos.csv\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# ETAPA 1: CARGA Y EXPLORACIÓN INICIAL\n",
    "# ============================================================================\n",
    "\n",
    "def cargar_dataset(filename: str) -> pd.DataFrame | None:\n",
    "    try:\n",
    "        base_dir = os.getcwd()\n",
    "        file_path = os.path.join(base_dir, \"..\", \"data\", filename)\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"El archivo {file_path} no existe.\")\n",
    "\n",
    "        ext = os.path.splitext(filename)[1].lower()\n",
    "\n",
    "        if ext == \".csv\":\n",
    "            # Intentar abrir con UTF-8, si falla usar latin-1\n",
    "            for encoding in [\"utf-8\", \"latin-1\"]:\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding=encoding) as f:\n",
    "                        sample = f.read(2048)\n",
    "                        sniffer = csv.Sniffer()\n",
    "                        dialect = sniffer.sniff(sample)\n",
    "                        detected_sep = dialect.delimiter\n",
    "\n",
    "                    data = pd.read_csv(file_path, encoding=encoding, sep=detected_sep)\n",
    "                    break  # Si carga correctamente, salir del bucle\n",
    "                except UnicodeDecodeError:\n",
    "                    continue\n",
    "            else:\n",
    "                raise UnicodeDecodeError(\"No se pudo decodificar el archivo con utf-8 ni latin-1\")\n",
    "\n",
    "        elif ext in [\".xls\", \".xlsx\"]:\n",
    "            data = pd.read_excel(file_path)\n",
    "        else:\n",
    "            raise ValueError(\"Formato de archivo no soportado. Use CSV o Excel (.xls, .xlsx).\")\n",
    "\n",
    "        print(f\">>> El archivo '{filename}' se cargó correctamente. Filas: {data.shape[0]}, Columnas: {data.shape[1]}\")\n",
    "        return data\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error de formato: {e}\")\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error inesperado: {e}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def explorar_dataset(df):\n",
    "    \"\"\"\n",
    "    Muestra información básica del dataset\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXPLORACIÓN INICIAL DEL DATASET\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n1. Primeras filas:\")\n",
    "    display(df.head(3))\n",
    "    \n",
    "    print(\"\\n2. Información de columnas:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\n3. Valores nulos por columna:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    print(\"\\n4. Valores únicos en columnas clave:\")\n",
    "    for col in ['flightNumber', 'plane', 'dep_airport_code', 'arr_airport_code']:\n",
    "        if col in df.columns:\n",
    "            print(f\"  - {col}: {df[col].nunique()} valores únicos\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "454327d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> El archivo 'alojamientos_turisticos.csv' se cargó correctamente. Filas: 10974, Columnas: 14\n"
     ]
    }
   ],
   "source": [
    "df = cargar_dataset('alojamientos_turisticos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fef099ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# ETAPA 2: NORMALIZACIÓN DE NOMBRES DE COLUMNAS\n",
    "# ============================================================================\n",
    "\n",
    "def normalizar_nombres_columnas(df):\n",
    "    \"\"\"\n",
    "    Convierte nombres de columnas a snake_case sin tildes ni caracteres especiales\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"NORMALIZACIÓN DE NOMBRES DE COLUMNAS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    def a_snake_case(texto):\n",
    "        # Eliminar tildes\n",
    "        texto = texto.replace('á', 'a').replace('é', 'e').replace('í', 'i')\n",
    "        texto = texto.replace('ó', 'o').replace('ú', 'u').replace('ñ', 'n')\n",
    "        texto = texto.replace('Á', 'A').replace('É', 'E').replace('Í', 'I')\n",
    "        texto = texto.replace('Ó', 'O').replace('Ú', 'U').replace('Ñ', 'N')\n",
    "        \n",
    "        # Convertir a minúsculas\n",
    "        texto = texto.lower()\n",
    "        \n",
    "        # Reemplazar espacios y caracteres especiales por guión bajo\n",
    "        texto = re.sub(r'[^a-z0-9]+', '_', texto)\n",
    "        \n",
    "        # Eliminar guiones bajos al inicio y final\n",
    "        texto = texto.strip('_')\n",
    "        \n",
    "        return texto\n",
    "    \n",
    "    columnas_originales = df.columns.tolist()\n",
    "    columnas_nuevas = [a_snake_case(col) for col in columnas_originales]\n",
    "    \n",
    "    df.columns = columnas_nuevas\n",
    "    \n",
    "    print(f\"\\n✓ Nombres de columnas normalizados\")\n",
    "    print(f\"  Total de columnas: {len(columnas_nuevas)}\")\n",
    "    print(\"\\nEjemplos de cambios:\")\n",
    "    for orig, nuevo in list(zip(columnas_originales, columnas_nuevas))[:5]:\n",
    "        if orig != nuevo:\n",
    "            print(f\"  '{orig}' → '{nuevo}'\")\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "215d6ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "NORMALIZACIÓN DE NOMBRES DE COLUMNAS\n",
      "================================================================================\n",
      "\n",
      "✓ Nombres de columnas normalizados\n",
      "  Total de columnas: 14\n",
      "\n",
      "Ejemplos de cambios:\n"
     ]
    }
   ],
   "source": [
    "# 3. Normalizar nombres de columnas\n",
    "df = normalizar_nombres_columnas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6115c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# ETAPA 3: LIMPIEZA DE VALORES NULOS Y MARCADORES\n",
    "# ============================================================================\n",
    "\n",
    "def limpiar_valores_nulos(df):\n",
    "    \"\"\"\n",
    "    Convierte marcadores de nulo (\"-\", espacios vacíos, etc.) a NaN\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LIMPIEZA DE VALORES NULOS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Reemplazar \"-\" y strings vacíos por NaN\n",
    "    df = df.replace(['-', '', ' ', 'nan', 'NaN'], np.nan)\n",
    "    \n",
    "    # Limpiar espacios en blanco en columnas de texto\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    \n",
    "    print(f\"\\n✓ Valores nulos limpiados\")\n",
    "    print(f\"\\nValores nulos por columna:\")\n",
    "    nulos = df.isnull().sum()\n",
    "    print(nulos[nulos > 0])\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "08cbdd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LIMPIEZA DE VALORES NULOS\n",
      "================================================================================\n",
      "\n",
      "✓ Valores nulos limpiados\n",
      "\n",
      "Valores nulos por columna:\n",
      "denominacion     2326\n",
      "via_nombre         16\n",
      "numero             13\n",
      "bloque          10787\n",
      "portal          10530\n",
      "escalera         9830\n",
      "planta           2136\n",
      "puerta           2867\n",
      "cdpostal          650\n",
      "localidad           3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4. Limpiar valores nulos\n",
    "df = limpiar_valores_nulos(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ca13ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# ETAPA 4: PROBLEMA 3 - NORMALIZACIÓN DE CAMPOS DE DIRECCIÓN\n",
    "# ============================================================================\n",
    "\n",
    "def normalizar_direccion(df):\n",
    "    \"\"\"\n",
    "    Normaliza campos de dirección: via_tipo, via_nombre, planta, puerta\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROBLEMA 3: NORMALIZACIÓN DE DIRECCIÓN\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Normalizar via_tipo a mayúsculas\n",
    "    if 'via_tipo' in df.columns:\n",
    "        df['via_tipo'] = df['via_tipo'].str.upper()\n",
    "        print(f\"\\n✓ via_tipo normalizado a mayúsculas\")\n",
    "        print(f\"  Valores únicos: {df['via_tipo'].unique()}\")\n",
    "    \n",
    "    # Normalizar via_nombre: primera letra mayúscula\n",
    "    if 'via_nombre' in df.columns:\n",
    "        df['via_nombre'] = df['via_nombre'].apply(\n",
    "            lambda x: x.title() if isinstance(x, str) else x\n",
    "        )\n",
    "        print(f\"\\n✓ via_nombre normalizado (Title Case)\")\n",
    "    \n",
    "    # Normalizar planta: extraer solo el número\n",
    "    if 'planta' in df.columns:\n",
    "        def limpiar_planta(valor):\n",
    "            if pd.isna(valor):\n",
    "                return None\n",
    "            valor_str = str(valor)\n",
    "            # Extraer solo dígitos\n",
    "            numeros = re.findall(r'\\d+', valor_str)\n",
    "            return numeros[0] if numeros else None\n",
    "        \n",
    "        df['planta'] = df['planta'].apply(limpiar_planta)\n",
    "        print(f\"\\n✓ planta normalizada (solo números)\")\n",
    "        print(f\"  Valores únicos: {df['planta'].unique()}\")\n",
    "    \n",
    "    # Normalizar puerta: mapeo de abreviaciones\n",
    "    if 'puerta' in df.columns:\n",
    "        mapeo_puerta = {\n",
    "            'DCHA.': 'Derecha',\n",
    "            'DCHA': 'Derecha',\n",
    "            'D': 'Derecha',\n",
    "            'IZDA.': 'Izquierda',\n",
    "            'IZDA': 'Izquierda',\n",
    "            'I': 'Izquierda',\n",
    "            'IZ': 'Izquierda',\n",
    "            'EXT_IZ': 'Exterior Izquierda',\n",
    "            'PTA. I': 'Izquierda'\n",
    "        }\n",
    "        \n",
    "        df['puerta'] = df['puerta'].apply(\n",
    "            lambda x: mapeo_puerta.get(str(x).upper(), x) if pd.notna(x) else x\n",
    "        )\n",
    "        print(f\"\\n✓ puerta normalizada\")\n",
    "        print(f\"  Valores únicos: {df['puerta'].unique()}\")\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "26e36618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROBLEMA 3: NORMALIZACIÓN DE DIRECCIÓN\n",
      "================================================================================\n",
      "\n",
      "✓ via_tipo normalizado a mayúsculas\n",
      "  Valores únicos: ['PASEO' 'CALLE' 'CRA' 'PLAZA' 'CUSTA' 'AVDA' 'CTRA' 'AVIA' 'BULEV'\n",
      " 'CSTAN' 'GTA' 'TRVA' 'COL' 'CMNO' 'RONDA' 'FINCA' 'PRAJE' 'CLLJA' 'PSAJE'\n",
      " 'CLLON' 'URB' 'PZO' 'BARRO' 'SECT' 'DISEM' 'RTDA' 'POLIG' 'LUGAR' 'EXTRR']\n",
      "\n",
      "✓ via_nombre normalizado (Title Case)\n",
      "\n",
      "✓ planta normalizada (solo números)\n",
      "  Valores únicos: [None '3' '8' '4' '2' '5' '1' '7' '9' '6' '41' '3568' '1234' '0' '20' '14'\n",
      " '13' '10' '11' '25' '24' '19' '16' '12' '15' '22' '00' '01' '02' '102'\n",
      " '104' '110' '111' '208' '311' '402' '405' '406' '408' '410' '501' '602'\n",
      " '610' '702' '705' '706' '709' '710' '801' '802' '803' '804' '805' '806'\n",
      " '807' '401' '210' '106' '223' '219' '274' '04']\n",
      "\n",
      "✓ puerta normalizada\n",
      "  Valores únicos: [nan 'Derecha' '2' 'Exterior Izquierda' 'A' 'Izquierda' 'C' '3' 'B' '1'\n",
      " 'IZQ.' 'IZ DCH' 'A y B' '5 y 6' 'CENTRO' 'B y C' 'IZQDA' 'DHA' 'H' 'F'\n",
      " 'DRCHA' 'A C D' 'PTA. D' 'EXT. I' 'Ext.' 'EXT' 'DHCA' 'PTA. 1' 'LOC. 1'\n",
      " '0' 'LOCAL' '1 Y 2' '4' '6' 'EXT DC' 'G' 'INT' 'J' '13' '14' '11'\n",
      " 'DCHA A' '9' '8' '20' '23' '22' '19' '7' 'A3' 'A1' 'H IZDA' '3 B'\n",
      " 'EXT IZ' 'B-IZDA' 'PTA. 4' '3D' 'IZQ. A' '1 G' 'INT D' 'CENT D' '3 C'\n",
      " 'PTA. 2' '5' 'CTRO' '18' '21' '24' 'IZQ. B' '209' '114' '221' 'E' '2, A'\n",
      " 'INT DC' 'IA' '2 IZQ.' 'K' '12' '16' '10' 'P' 'ÁTICO' 'PTA 81' 'IZDA-2'\n",
      " 'YI' 'VT-1' 'Izq.' 'D1' 'I1' 'IZ.' 'DRCH' 'BAJ' 'EXT D' 'L' 'CTRO.' 'C A'\n",
      " '1 I' '409' '110' '406' '35' 'INT A' 'Int.' 'CENTR' '1 A' '41' '34'\n",
      " 'CI IZ' 'YD' 'ED' 'EI' 'CD' '27' 'YN' 'EXT.' 'INT.' '42' 'CN' '806'\n",
      " '1402' 'BC-1' 'A-B' 'IB' 'IZDA.A' '211' '310' 'L3' '7C' '15' '405' '611'\n",
      " '410' 'B BIS' 'D2' 'O' '407' 'IZ-C' 'D6' '1632' 'IZQ. 2' 'DC' '613' 'IZQ'\n",
      " '1114' 'A2' 'CTR-DC' 'B-2' 'C-1' 'IZQ. 1' 'R' 'N' '1D' 'DR' 'INTERI'\n",
      " 'DCH' 'IZD' '414' '17' '120' 'D EXT' '81' 'Q' 'EX D' '307' 'DER' 'PTA. 9'\n",
      " '909' '1002' '1003' '1102' '1104' 'PTA. C' 'PTA. B' 'PTA. A' 'PTA. 8'\n",
      " 'PTA. 7' 'PTA. 3' 'PTA. 5' 'PTA. 6' 'PTA. E' 'EXT. C' 'DCHA.1' '1305'\n",
      " '1308' '1507' '1510' 'Dcha 4' 'VP' '706' '1214' 'PTA. H' 'PTA. G'\n",
      " 'PTA. F' 'INT. D' 'INT. C' 'INT. B' 'Y1' '53' 'A-23' 'PTA.' 'INT. I'\n",
      " 'EXT. H' 'C IZQ' 'CTRO D' 'PTA.IZ' 'EXT. D' 'EXT. E' 'INT. E' 'ESC 2'\n",
      " 'INT. 3' '601' 'Nº 3' 'ES' 'UN' 'C IZQ.' '825' '827' 'Dc.ext' 'DCHA 1'\n",
      " 'Izq. 2' '435' 'EXT. A' 'INT.DC' 'BAJO' 'ESP' 'CI' 'ESC 1' '4 BIS' '602'\n",
      " 'B-1' 'IZQDA.' 'Y3' '701' 'EXT. 6' 'EXT. 7' 'INT. 1' 'I-B' 'I-A' 'Int.D'\n",
      " '3 Izq.' 'EXT 1' 'PTA I4' 'PTA.DC' '111' 'ESC1 P' '158' 'Centro' 'PTA. 0'\n",
      " 'ESC. 1' 'L5' 'ID' 'ESC1 I' 'PPAL C' '1-I' '33' 'Ct.Izq' 'Dcha.B'\n",
      " 'C DCHA' 'APTO.2' 'E2' 'A-213' 'ESC Y' 'A-302' 'IZDA A' '308' 'Ext.Iz'\n",
      " 'F-B' 'PTA. Y' 'PTA.B2' '26' 'PTA..' 'PTA.1' '51' 'L1' '723' '50' '52'\n",
      " 'EXT. B' '328' 'H DCH' 'H IZQ' 'DC. A' 'DC B' 'E4' '1 C' 'PTA.,' 'PTA.11'\n",
      " 'PTA.12' 'EXT. 4' '534' '1 B' 'INT. A' 'INT. 6' '618' '714' '204' 'PTA F'\n",
      " '2 IZQ' '2 CTRO' 'INT 2' 'INT 5' '303' '161' 'CT DR' '5-7' '323' '2 DCH'\n",
      " 'CT INT' '510' 'V2' 'M' 'C-I' 'C-D' 'C-I-A' 'C-I-B' '30' '807' 'DCHA 6'\n",
      " 'ESC. 4' '6D' '151' 'IZQ A' 'D4' 'DCHA,' 'F1' '205' 'B3' '220' 'PTA.D'\n",
      " 'BAJO 1' 'BAJO 2' 'C1' 'Int Iz' 'L6' '515' 'C-2' '25' '805' 'BC' 'CA'\n",
      " 'Ctro.' 'EC' '212' '113' 'IZQ C' '10-11' '43' '322' '2216' 'B2' 'DR 2'\n",
      " 'DR2' 'EXT. 2' 'INT. 8' 'DCH1' 'CNT' 'B IZQ' 'IZQ. C' 'INT.IZ' '422B'\n",
      " 'B IZQ.' 'Izd.' '1119' '1121' '1207' 'IZQ 1' 'IZQ. D' '8 I' '108' 'E-D'\n",
      " 'BAJO D' 'D IZQ.' '1B' 'Y' 'IC' '417' 'A DCH' 'A IZQ' '150' '153' 'E1'\n",
      " '320' 'EXT.DC' 'INT IZ' 'CENT' '1IZDA' 'a' 'L-10' 'Dch' 'Centr' '1º DCH'\n",
      " 'ABCD' '--' '82N' '19A' '19B' '20C' 'Izd' 'calle' 'FD' 'L-35' 'L-30'\n",
      " 'L-20' 'DERECH' 'LC1' 'L10' 'ext.iz' 'II' 'IZQ.1' '3 INT' 'ATICO' 'B1'\n",
      " 'C2' 'PTA.CT' 'PTA CT' 'IZDA B' 'CTR DR' '2E' 'CT-DCH' 'IZ. B' 'DE. A'\n",
      " 'C9' 'CD-CI' 'VUT1' 'NORTE' 'SUR' 'CD,C' '5 INT' '28' 'DCH. A' 'PTA.IN'\n",
      " 'AB' '119' 'PTA.EX' 'BIS A' 'L DCHA' 'CHA.' 'DUP. I' 'DUP. D' 'DER.'\n",
      " 'C EX' 'DA' 'PTA.01' 'C-DER' 'PB' 'ESC2 P' '3.3' '4A' 'C BIS' '37' '32'\n",
      " 'UNICA' '1 DCHA' 'DR A' 'DR B' '610 A' 'IZQUI' 'C Y D' '01' 'A 2' 'Drch'\n",
      " '116' 'VT-2' 'L20' '1A' 'CTR' '03' '302' '07' 'izda 1' '08' '3B' '109'\n",
      " '3C' '3A' 'A,BC,D' '6F' '1A2' '02' '. 2' 'Dcha 2' '09' 'DCHO.' '122'\n",
      " '44B' 'L50' 'L-22' 'IZ B' '82-I' 'IZDO.' 'T dch' 'A BIS' '215' 'CALL'\n",
      " 'L9' '4-A' 'A-F' 'Traser' 'L-15' 'L-17' 'LC3' 'ABC' 'L40' '2 Y 7' '06'\n",
      " '---' 'U' 'EXT-IZ' '3-4 po' 'Izquie' '1109' '832' '130' '3.2' 'E3' 'F2'\n",
      " '20D' '123' '208' '725' '623' '615' '617' '614' '1-2' '1-3' '823' '821'\n",
      " '818' '530' '1-4' '1-5' '1-6' '1-8' '222' '524' '522' '518' '514' '1-7'\n",
      " 'Ex. Dr' '107' 'Viv. 1' '408' '1C' '1Y2' '433' '431' '5-2' '213' '105'\n",
      " '214' 'B-3' '1411' 'N3-03' 'LOC. 2' '20E' 'L10 B' '225' '121' 'L-60'\n",
      " '811' '810' '736' '331' '329' '327' '325' '508' '505' '434' '3.1' 'L30'\n",
      " '3-1' '4 - V1' '4 - V2' '4 - V3' '1410' '1110' '1004' '1001' '912' '907'\n",
      " '910' '904' '634' '632' '629' '625' '428' '129' '007' 'V5' '01 B' '01 C'\n",
      " 'L10-A' 'A6' 'EXTERI' '112' '721' '201' '203' '2A' 'Derech' '118' '2-1'\n",
      " '1-1' '117' 'L2' '708' 'L-50' '1212' '427' '426' '424' '423' '421' '420'\n",
      " '828' '826' '824' '2B2' '1409' '401' '1311' '1309' '1307' '831' '829'\n",
      " 'L-40' 'DCHA/I' '66b' '1210' '1208' '1508' '1503' '533' '101' 'IZQUIE'\n",
      " 'Loc.22' '4B' '102' '4C' '4 Y 5' '718' '715' 'V1' 'V4' '1009' '1008'\n",
      " '1007' '1005' 'IZQD' '3-2' 'B-C' '25 N2' '2A2' '1111' '217' 'b' 'IZQ/DR'\n",
      " '728' 'LOC-10' '735' '730' '536' '535' 'V-17' '103' '4D' '817' '813'\n",
      " '816' '608' '605' '603' '125' '128' 'c' '2B' '2-A' '224' '3ºB-B' 'L-4B'\n",
      " '1011' '40' '142' '207' '127' '255' 's/n' 'Local' 'V3' '1506' '1108'\n",
      " '1106' '419' '412' '2A1' 'N-02' '528' '526' 'EXT3' '5-3' '70' 'L 10 B'\n",
      " '106' '206' 'A7' '7-1' '24-3' '507' 'DC IZQ' 'OS' 'L14' '2-2' '124'\n",
      " 'chalet' 'L-11C' '006' 'L210' '5-1' '7-2' 'DCH V1' 'DCH V2' 'IZDA 1'\n",
      " 'LC2' '01 L14' '1-B' '223' '01 A' 'DCHA 2' '202' '301' '2 Y 3' '11B'\n",
      " '3ºB- A' 'L4' '415' '439' '2 y 3' 'N3-1' '9B' '3BB' 'B-4' 'local' '218'\n",
      " '1012' '11A' '251' '272' 'DRCH D' '638' '335' '216' 'IZDA 2' '7-3' '521'\n",
      " '05' '42G' '263' '29' 'A5' 'L 10 C' 'L2BIS' '537' '6-1' '4BIS' '516'\n",
      " '24-1' 'IZDA 3' 'IZDA 4' 'No' 'S' '246' '1IZ' '340' 'C y D' '135' '274'\n",
      " 'L10 A' 'L 10 D' '25 Nº1' '24-2' '9A' 'izq' '6-2' 'Izq ex' 'E y F' '711'\n",
      " 'DCH IZ' 'IZQA' '9 y 10']\n"
     ]
    }
   ],
   "source": [
    "# 5. Normalizar dirección (Problema 3)\n",
    "df = normalizar_direccion(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9e09b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# ETAPA 5: PROBLEMA 4 - SEPARACIÓN DE TIPO Y CATEGORÍA\n",
    "# ============================================================================\n",
    "\n",
    "def separar_tipo_categoria(df):\n",
    "    \"\"\"\n",
    "    Separa el campo 'categoria' en 'categoria_nivel' (numérico) y 'categoria_tipo' (texto)\n",
    "    Normaliza 'alojamiento_tipo'\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROBLEMA 4: SEPARACIÓN DE TIPO Y CATEGORÍA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if 'categoria' in df.columns:\n",
    "        # Extraer nivel (número) y tipo (texto) de 'categoria'\n",
    "        # Ejemplo: \"3-HOTEL\" → nivel=3, tipo=\"HOTEL\"\n",
    "        \n",
    "        def extraer_nivel(valor):\n",
    "            if pd.isna(valor):\n",
    "                return None\n",
    "            match = re.match(r'^(\\d+)', str(valor))\n",
    "            return int(match.group(1)) if match else None\n",
    "        \n",
    "        def extraer_tipo(valor):\n",
    "            if pd.isna(valor):\n",
    "                return None\n",
    "            match = re.search(r'-(.+)$', str(valor))\n",
    "            return match.group(1).strip() if match else str(valor)\n",
    "        \n",
    "        df['categoria_nivel'] = df['categoria'].apply(extraer_nivel)\n",
    "        df['categoria_tipo'] = df['categoria'].apply(extraer_tipo)\n",
    "        \n",
    "        print(f\"\\n✓ Campo 'categoria' separado en:\")\n",
    "        print(f\"  - categoria_nivel (numérico): {df['categoria_nivel'].unique()}\")\n",
    "        print(f\"  - categoria_tipo (texto): {df['categoria_tipo'].unique()}\")\n",
    "    \n",
    "    # Normalizar alojamiento_tipo a mayúsculas\n",
    "    if 'alojamiento_tipo' in df.columns:\n",
    "        df['alojamiento_tipo'] = df['alojamiento_tipo'].str.upper()\n",
    "        print(f\"\\n✓ alojamiento_tipo normalizado\")\n",
    "        print(f\"  Valores únicos: {df['alojamiento_tipo'].unique()}\")\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d956de7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROBLEMA 4: SEPARACIÓN DE TIPO Y CATEGORÍA\n",
      "================================================================================\n",
      "\n",
      "✓ Campo 'categoria' separado en:\n",
      "  - categoria_nivel (numérico): [ 3.  2. nan  1.  4.  5.]\n",
      "  - categoria_tipo (texto): ['HOTEL' 'PENSION' 'HOSTAL' 'CASA HUESPEDES' '5 estrellas L'\n",
      " 'HOTEL-APART.' 'APARTAMENTO RURAL' 'HOJA DE ROBLE' 'CASA RURAL'\n",
      " 'APART-TURISTICO' 'SIN CATEGORIA' 'CAMPING']\n",
      "\n",
      "✓ alojamiento_tipo normalizado\n",
      "  Valores únicos: ['HOTEL' 'PENSION' 'HOSTAL' 'CASA HUESPEDES' 'HOTEL-APART.'\n",
      " 'APARTAMENTO RURAL' 'HOTEL RURAL' 'CASA RURAL' 'APART-TURISTICO'\n",
      " 'HOSTERIAS' 'VIVIENDAS DE USO TU' 'CAMPING']\n"
     ]
    }
   ],
   "source": [
    "# 6. Separar tipo y categoría (Problema 4)\n",
    "df = separar_tipo_categoria(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "47603bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# ETAPA 6: VALIDACIÓN Y RESUMEN FINAL\n",
    "# ============================================================================\n",
    "\n",
    "def validar_limpieza(df):\n",
    "    \"\"\"\n",
    "    Valida que la limpieza se haya realizado correctamente\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"VALIDACIÓN Y RESUMEN FINAL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\n--- Dimensiones finales ---\")\n",
    "    print(f\"  Registros: {len(df)}\")\n",
    "    print(f\"  Columnas: {len(df.columns)}\")\n",
    "    \n",
    "    print(f\"\\n--- Tipos de datos ---\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    print(f\"\\n--- Valores nulos totales ---\")\n",
    "    total_nulos = df.isnull().sum().sum()\n",
    "    total_valores = df.shape[0] * df.shape[1]\n",
    "    porcentaje_nulos = (total_nulos / total_valores) * 100\n",
    "    print(f\"  Total: {total_nulos} ({porcentaje_nulos:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\n--- Primeras 3 filas del dataset limpio ---\")\n",
    "    print(df.head(3))\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8c2aff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VALIDACIÓN Y RESUMEN FINAL\n",
      "================================================================================\n",
      "\n",
      "--- Dimensiones finales ---\n",
      "  Registros: 10974\n",
      "  Columnas: 16\n",
      "\n",
      "--- Tipos de datos ---\n",
      "alojamiento_tipo     object\n",
      "categoria            object\n",
      "denominacion         object\n",
      "via_tipo             object\n",
      "via_nombre           object\n",
      "numero               object\n",
      "bloque               object\n",
      "portal               object\n",
      "escalera             object\n",
      "planta               object\n",
      "puerta               object\n",
      "cdpostal            float64\n",
      "localidad            object\n",
      "signatura            object\n",
      "categoria_nivel     float64\n",
      "categoria_tipo       object\n",
      "dtype: object\n",
      "\n",
      "--- Valores nulos totales ---\n",
      "  Total: 50416 (28.71%)\n",
      "\n",
      "--- Primeras 3 filas del dataset limpio ---\n",
      "  alojamiento_tipo  categoria  denominacion via_tipo       via_nombre numero  \\\n",
      "0            HOTEL    3-HOTEL  GRAN LEGAZPI    PASEO    De La Chopera     71   \n",
      "1          PENSION  2-PENSION        ISABEL    CALLE      De La Salud     13   \n",
      "2           HOSTAL   2-HOSTAL        BESAYA    CALLE  De San Bernardo     13   \n",
      "\n",
      "  bloque portal escalera planta puerta  cdpostal localidad signatura  \\\n",
      "0    NaN    NaN      NaN   None    NaN   28045.0    Madrid    HM-127   \n",
      "1    NaN    NaN      NaN      3    NaN   28013.0    Madrid    HM-132   \n",
      "2    NaN    NaN      NaN      8    NaN   28015.0    Madrid    HM-139   \n",
      "\n",
      "   categoria_nivel categoria_tipo  \n",
      "0              3.0          HOTEL  \n",
      "1              2.0        PENSION  \n",
      "2              2.0         HOSTAL  \n"
     ]
    }
   ],
   "source": [
    "# 7. Validar limpieza\n",
    "df_final = validar_limpieza(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a212fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# ETAPA 7: EXPORTACIÓN A JSON\n",
    "# ============================================================================\n",
    "\n",
    "def safe_value(v):\n",
    "    \"\"\"\n",
    "    Convierte valores NaN de pandas a None (que será null en JSON).\n",
    "    Convierte Timestamp a string ISO 8601.\n",
    "    Convierte numpy types a tipos nativos de Python.\n",
    "    \"\"\"\n",
    "    if pd.isna(v):\n",
    "        return None\n",
    "    \n",
    "    # Convertir Timestamp de pandas a string ISO 8601\n",
    "    if isinstance(v, pd.Timestamp):\n",
    "        return v.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    \n",
    "    # Convertir numpy types a tipos nativos de Python\n",
    "    if isinstance(v, (np.integer, )):\n",
    "        return int(v)\n",
    "    if isinstance(v, (np.floating, )):\n",
    "        return float(v)\n",
    "    \n",
    "    # Convertir datetime de Python a string ISO 8601\n",
    "    if isinstance(v, datetime):\n",
    "        return v.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    \n",
    "    return v\n",
    "\n",
    "\n",
    "def transformar_a_json_estructura(df):\n",
    "    \"\"\"\n",
    "    Transforma el DataFrame limpio a estructura JSON para alojamientos\n",
    "    \n",
    "    Returns:\n",
    "        Lista de diccionarios con la estructura JSON de alojamientos\n",
    "    \"\"\"\n",
    "    alojamientos_json = []\n",
    "    ts = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Crear documento base\n",
    "        alojamiento = {\n",
    "            \"alojamiento_id\": int(idx) + 1,  # ID secuencial\n",
    "            \"timestamp\": ts,\n",
    "            \"datos\": {}\n",
    "        }\n",
    "        \n",
    "        # Añadir todos los campos del DataFrame\n",
    "        for col in df.columns:\n",
    "            alojamiento[\"datos\"][col] = safe_value(row[col])\n",
    "        \n",
    "        alojamientos_json.append(alojamiento)\n",
    "    \n",
    "    return alojamientos_json\n",
    "\n",
    "\n",
    "def exportar_json(alojamientos_json, ruta_salida='dataset2_alojamientos_limpio.json', \n",
    "                  num_documentos=None, indent=2):\n",
    "    \"\"\"\n",
    "    Exporta la lista de alojamientos a un archivo JSON\n",
    "    \n",
    "    Args:\n",
    "        alojamientos_json: lista de diccionarios con estructura de alojamientos\n",
    "        ruta_salida: ruta del archivo JSON de salida\n",
    "        num_documentos: número de documentos a exportar. Si es None, exporta todos.\n",
    "        indent: nivel de indentación para legibilidad\n",
    "    \"\"\"\n",
    "    # Determinar cuántos documentos exportar\n",
    "    if num_documentos is None:\n",
    "        documentos_a_exportar = alojamientos_json\n",
    "        total_exportado = len(alojamientos_json)\n",
    "    else:\n",
    "        documentos_a_exportar = alojamientos_json[:num_documentos]\n",
    "        total_exportado = min(num_documentos, len(alojamientos_json))\n",
    "    \n",
    "    # Exportar a JSON\n",
    "    with open(ruta_salida, 'w', encoding='utf-8') as f:\n",
    "        json.dump(documentos_a_exportar, f, ensure_ascii=False, indent=indent)\n",
    "    \n",
    "    print(f\"\\n✓ Archivo JSON exportado: {ruta_salida}\")\n",
    "    print(f\"  Total de alojamientos exportados: {total_exportado}\")\n",
    "    print(f\"  Total de alojamientos disponibles: {len(alojamientos_json)}\")\n",
    "    \n",
    "    if num_documentos and num_documentos < len(alojamientos_json):\n",
    "        print(f\"  ⚠ Se exportaron solo los primeros {num_documentos} documentos\")\n",
    "    \n",
    "    tamanio_kb = round(len(json.dumps(documentos_a_exportar, ensure_ascii=False)) / 1024, 2)\n",
    "    print(f\"  Tamaño del archivo: {tamanio_kb} KB\")\n",
    "\n",
    "\n",
    "def mostrar_ejemplo_json(alojamientos_json, num_ejemplos=2):\n",
    "    \"\"\"\n",
    "    Muestra ejemplos del JSON generado\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"EJEMPLOS DE DOCUMENTOS JSON GENERADOS (primeros {num_ejemplos})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, alojamiento in enumerate(alojamientos_json[:num_ejemplos], 1):\n",
    "        print(f\"\\n--- Alojamiento {i} ---\")\n",
    "        print(json.dumps(alojamiento, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4178d7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EJEMPLOS DE DOCUMENTOS JSON GENERADOS (primeros 2)\n",
      "================================================================================\n",
      "\n",
      "--- Alojamiento 1 ---\n",
      "{\n",
      "  \"alojamiento_id\": 1,\n",
      "  \"timestamp\": \"2025-11-28T01:11:48\",\n",
      "  \"datos\": {\n",
      "    \"alojamiento_tipo\": \"HOTEL\",\n",
      "    \"categoria\": \"3-HOTEL\",\n",
      "    \"denominacion\": \"GRAN LEGAZPI\",\n",
      "    \"via_tipo\": \"PASEO\",\n",
      "    \"via_nombre\": \"De La Chopera\",\n",
      "    \"numero\": \"71\",\n",
      "    \"bloque\": null,\n",
      "    \"portal\": null,\n",
      "    \"escalera\": null,\n",
      "    \"planta\": null,\n",
      "    \"puerta\": null,\n",
      "    \"cdpostal\": 28045.0,\n",
      "    \"localidad\": \"Madrid\",\n",
      "    \"signatura\": \"HM-127\",\n",
      "    \"categoria_nivel\": 3.0,\n",
      "    \"categoria_tipo\": \"HOTEL\"\n",
      "  }\n",
      "}\n",
      "\n",
      "--- Alojamiento 2 ---\n",
      "{\n",
      "  \"alojamiento_id\": 2,\n",
      "  \"timestamp\": \"2025-11-28T01:11:48\",\n",
      "  \"datos\": {\n",
      "    \"alojamiento_tipo\": \"PENSION\",\n",
      "    \"categoria\": \"2-PENSION\",\n",
      "    \"denominacion\": \"ISABEL\",\n",
      "    \"via_tipo\": \"CALLE\",\n",
      "    \"via_nombre\": \"De La Salud\",\n",
      "    \"numero\": \"13\",\n",
      "    \"bloque\": null,\n",
      "    \"portal\": null,\n",
      "    \"escalera\": null,\n",
      "    \"planta\": \"3\",\n",
      "    \"puerta\": null,\n",
      "    \"cdpostal\": 28013.0,\n",
      "    \"localidad\": \"Madrid\",\n",
      "    \"signatura\": \"HM-132\",\n",
      "    \"categoria_nivel\": 2.0,\n",
      "    \"categoria_tipo\": \"PENSION\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 8. Transformar a JSON\n",
    "alojamientos_json = transformar_a_json_estructura(df_final)\n",
    "mostrar_ejemplo_json(alojamientos_json, num_ejemplos=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bfebb186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Archivo JSON exportado: dataset2_alojamientos_muestra_100.json\n",
      "  Total de alojamientos exportados: 100\n",
      "  Total de alojamientos disponibles: 10974\n",
      "  ⚠ Se exportaron solo los primeros 100 documentos\n",
      "  Tamaño del archivo: 41.72 KB\n",
      "\n",
      "================================================================================\n",
      "PROCESO COMPLETADO\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 9. Exportar JSON completo\n",
    "#exportar_json(alojamientos_json, ruta_salida='dataset2_alojamientos_limpio.json')\n",
    " \n",
    "# 10. (Opcional) Exportar solo una muestra para pruebas\n",
    "exportar_json(alojamientos_json, ruta_salida='dataset2_alojamientos_muestra_100.json', num_documentos=100)\n",
    " \n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESO COMPLETADO\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76152cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d2814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "03_bases_datos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
